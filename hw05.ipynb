{"nbformat":4,"nbformat_minor":0,"metadata":{"interpreter":{"hash":"da2450b255984eba261d4f9cdee3330bd0d7728ee7fae9f7c2e273b8d0631fc6"},"kernelspec":{"name":"python3","display_name":"Python 3.7.10 64-bit ('gatsbi_rl': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"orig_nbformat":2,"colab":{"name":"hw05.ipynb의 사본","provenance":[{"file_id":"1p08o_pg2Ogq6zi2dcWsyXOm9XwYS8vf5","timestamp":1639024667249}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"vw6YB_7SA7zp"},"source":["# \n","\n","# Linear Algebra for Electrical Systems\n","## 2021-fall (430.216, Instructor: prof. Young Min Kim)\n","## TAs: Cheol-Hui Min and Junho Lee\n","\n","## HW5: Classification via Least Squares\n","---\n","\n","- In this homework, we will explore the applications of QR factorization and back substitution\n","we have implemented in the HW3 on the data science problems.\n","\n","- You will be asked to formulate a simple least squares solver using \n","methods we have implemented in HW3 `gram_schmidt`, `QR_factorization`, `back_subst`, and `solve_via_backsub`.\n","We provide those methods for your convenience.\n","\n","- This HW consists of 3 problems.\n","    - Problem 1. Constructing a simple least squares solver.\n","    - Problem 2. Classification of IRIS flower dataset.\n","    - Problem 3. Multi-class classification of IRIS flower dataset.\n"," \n","- Please fill out all the `Problem #K. fill out here.` annotated parts.\n","\n","- You should **NOT** use methods under `np.linalg` API. Please use generic `numpy` methods.\n"]},{"cell_type":"code","metadata":{"tags":[],"id":"Pd5fs1S6A7zz"},"source":["import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","%matplotlib inline\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FhU2eTcuA7z2"},"source":["## Problem 1. Constructing a simple least squares solver via QR factorization\n","---\n","We follow the pseudo code in the pp. 232 of our textbook, to solve least squares\n","via QR factorization.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U9YHA6GGA7z4"},"source":["First, let's prepare some ingredients we have implemented in HW3."]},{"cell_type":"code","metadata":{"id":"PuvUrwNuA7z5"},"source":["def norm(v):\n","    \"\"\"\n","        Compute the 2-norm of given vector.\n","        Input:\n","            a batch of vector of shape [N, D] \n","        Return:\n","            a batch of computed 2-norm of shape [N, D]\n","    \"\"\"\n","    # Assume we use Frobenious norm (Euclidean norm)\n","    return np.sqrt(np.sum(v**2, axis=-1))\n","\n","\n","def gram_schmidt(a):\n","    \"\"\"\n","    in: a - length k list of n-dim np.arrays.\n","    out: q - length k list of n-dim orthonormal np.arrays. \n","    \"\"\"\n","    q = []\n","    # orthogonalization\n","    for i in range(len(a)): # for i = 1, ..., k\n","        q_tilde = a[i]\n","        for j in range(len(q)): # for each dimension of q_tilde\n","            # recursively add dot(q)\n","            q_tilde = q_tilde - (np.dot(q[j], a[i]))*q[j]\n","        # Test for linear dependence. If \\tilde{q}_i = 0.\n","        if np.sqrt(sum(q_tilde**2)) <= 1e-10:\n","            print('Vectors are linearly dependent.')\n","            print('GS algorithm terminates at iteration ', i+1)\n","            return q\n","        #Normalization\n","        else:\n","            q_tilde = q_tilde / norm(q_tilde)\n","            q.append(q_tilde)\n","    return q\n","\n","\n","def QR_factorization(A):\n","    \"\"\"\n","    in: numpy array whose k columns are linearly independent.\n","    \"\"\"\n","    # we feed gram_schmidt() A.T since it orthonormalizes row vectors of the input array. \n","    # Thus, we get transposed array whose rows are orthonormal. \n","    Q_transpose = np.array(gram_schmidt(A.T))\n","    R = Q_transpose @ A # since Q^T = Q^-1\n","    Q = Q_transpose.T\n","    return Q, R\n","\n","\n","\n","# define the back-substitution function.\n","# please refer to pp.207 of our textbook.\n","def back_subst(R, b_tilde):\n","    n = R.shape[0]\n","    x = np.zeros(n)\n","    for i in reversed(range(n)): # iterate in reversed order: n, n-1, ..., 1.\n","        x[i] = b_tilde[i]\n","        for j in range(i+1, n):\n","            x[i] = x[i] - R[i,j] * x[j]\n","        x[i] = x[i]/R[i,i]\n","    return x\n","\n","\n","# define a solver the uses back_substituion.\n","def solve_via_backsub(A, b):\n","    # first to QR factorization\n","    Q, R = QR_factorization(A)\n","\n","    # let b_tilde as Q^T b\n","    b_tilde = Q.T @ b\n","\n","    # solve Rx=Q^Tb to get x.\n","    x = back_subst(R, b_tilde)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A3jFCI41A7z7"},"source":["<!-- If we choose $\\mathbf{\\tilde{q}}_1= \\mathbf{a}_1$, then the orthogonal component of projection of $\\mathbf{a}_2$ onto $\\mathbf{\\tilde{q}}_1$ is $\\mathbf{\\tilde{q}}_2$.\n","\n","\n","Define the projecttion of vector $\\mathbf{a}_2$ on the vector $\\mathbf{\\tilde{q}}_1$ as $\\text{Proj}_{\\mathbf{\\tilde{q}}_1}\\mathbf{a}_2 = \\alpha \\mathbf{a}_1$, \n","\n"," then $(\\mathbf{a}_2 - \\alpha \\mathbf{a}_1)\\cdot \\mathbf{a}_1 = 0$, rearange for $\\alpha$\n","\n","$$\n","\\alpha = \\frac{\\mathbf{a}_2^T\\mathbf{a}_1}{\\mathbf{a}_1^T\\mathbf{a}_1}\n","$$\n","\n","According to definition above\n","\n","$$\n","\\text{Proj}_{\\mathbf{\\tilde{q}}_1}\\mathbf{a}_2 = \\alpha \\mathbf{a}_1 = \\frac{\\mathbf{a}_2^T\\mathbf{a}_1}{\\mathbf{a}_1^T\\mathbf{a}_1}\\mathbf{a}_1\n","$$\n","\n","The orthogonal component, $\\mathbf{\\tilde{q}}_2$ is \n","\n","$$\n","\\mathbf{a}_2- \\text{Proj}_{\\mathbf{\\tilde{q}}_1}\\mathbf{a}_2 =\\mathbf{a}_2 - \\frac{\\mathbf{a}_2^T\\mathbf{a}_1}{\\mathbf{a}_1^T\\mathbf{a}_1}\\mathbf{a}_1\n","$$ -->"]},{"cell_type":"markdown","metadata":{"id":"KZcE1Aq4A7z9"},"source":["### First solve toy example with numpy's innate methods. "]},{"cell_type":"code","metadata":{"id":"H7G7_CipA70C"},"source":["# define a matrix having linearly independent columns.\n","A = np.array([[2, 0], [-1, 1], [0, 2]])\n","b = np.array([1, 0, -1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3ASZAgYpA70E"},"source":["In Eq.(12.5) and Eq.(12.6)of our textbook, we find that\n","\n","$\\mathbf{\\hat{x}}=(A^{\\top}A)^{-1}A^{\\top}\\mathbf{b}=A^{\\dagger}\\mathbf{b}$\n","\n","yields the solution for least squares problem.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T87HzCeKA70F","executionInfo":{"status":"ok","timestamp":1639023806161,"user_tz":-540,"elapsed":968,"user":{"displayName":"­이은후 / 학생 / 기계공학부","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv9QcASZ-Lrf5DcEF1J-lMM6zD0EnbwVb9y6c=s64","userId":"18289783074241175467"}},"outputId":"50a7eebf-01ca-431c-c538-c522ee8754c7"},"source":["# solve using the second term. use numpy.linalg.inv\n","sol1 = np.linalg.inv(A.T @ A) @ A.T @ b\n","print(sol1)\n","\n","# solve using the pinv solver of numpy.\n","sol2 = np.linalg.pinv(A)@ b\n","print(sol2)\n","\n","x_hat = sol2\n","# check of Eq.(12.4) holds.\n","np.allclose((A.T @ A) @ x_hat, A.T @ b)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 0.33333333 -0.33333333]\n","[ 0.33333333 -0.33333333]\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"4gFEd9GSA70I"},"source":["### Now we solve the approximate solution of least squares problem via QR factorization, referring to Algorithm 12.1."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xOoM2lMDA70J","executionInfo":{"status":"ok","timestamp":1639023806173,"user_tz":-540,"elapsed":125,"user":{"displayName":"­이은후 / 학생 / 기계공학부","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv9QcASZ-Lrf5DcEF1J-lMM6zD0EnbwVb9y6c=s64","userId":"18289783074241175467"}},"outputId":"8528d818-1ac0-491f-a412-d1e815dfc0ab"},"source":["A = np.random.normal(size = (100, 20))\n","b = np.random.normal(size = 100)\n","\n","# solve via our custom solver.\n","Q, R = QR_factorization(A)\n","x1 = np.linalg.inv(R) @ Q.T @ b # QR factorization 사용\n","x2 = np.linalg.inv(A.T @ A) @ (A.T @ b)\n","x3 = np.linalg.pinv(A) @ b\n","\n","print(np.allclose(x1, x2))\n","print(np.allclose(x1, x3))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","True\n"]}]},{"cell_type":"markdown","metadata":{"id":"3h4xmB_5A70K"},"source":["### Now we solve the lamp illumination problem."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n4tI6jjSA70L","executionInfo":{"status":"ok","timestamp":1639024011585,"user_tz":-540,"elapsed":768,"user":{"displayName":"­이은후 / 학생 / 기계공학부","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv9QcASZ-Lrf5DcEF1J-lMM6zD0EnbwVb9y6c=s64","userId":"18289783074241175467"}},"outputId":"5b686ad4-1c92-46f4-bcc5-81e810381e3e"},"source":["# number of lamps\n","n = 10\n","# x, y positions of lamps and height above floor \n","lamps = np.array([\n","        [4.1, 20.4, 4], [14.1, 21.3, 3.5], [22.6, 17.1, 6],\n","        [5.5, 12.3, 4.0], [12.2, 9.7, 4.0], [15.3, 13.8, 6],\n","        [21.3, 10.5, 5.5], [3.9 ,3.3, 5.0], [13.1, 4.3, 5.0],\n","        [20.3, 4.2, 4.5]\n","    ])\n","N = 25 # grid size\n","m = N * N # number of pixels\n","# construct m x 2 matrix with coordinates of pixel centers\n","\n","# print(np.outer(np.arange(0.5, N, 1),\n","#                             np.ones(N)).shape)\n","\n","\n","# assume we have 25 X 25 gridmap, where (0, 0) is the coordinate of top left corner \n","# and (25, 25) is the coordinate of bottom right corner.\n","# the center of each grid should have tho coordinate like\n","# [(0.5, 0.5), (1.5, 0.5), (2.5, 0.5) ... (24.5, 0.5)]\n","# [(0.5, 1.5), (1.5, 1.5), (2.5, 1.5)  ...(24.5, 1.5)]\n","#                          ...\n","# [(0.5, 24.5),            ...           (24.5, 24.5)]\n","\n","# define [625, 2] shaped array containing pixel coordinates.\n","\n","# first create equally spaced values in [0.5, 24.5], into 25 values.\n","spaces = np.linspace(0.5, 24.5, num = 25)\n","\n","# now we create value mesh for each horizontal (x) and vertical (y) axis\n","mesh_x, mesh_y = np.meshgrid(spaces, spaces)\n","\n","# create a mesh that each node containing the center coordinate and the zero\n","mesh = np.stack([mesh_x, mesh_y, np.zeros((25, 25))], axis=-1)\n","\n","# reshape for the computation convenience\n","mesh = mesh.reshape(-1, 3)\n","\n","# The m x n matrix A maps lamp powers to pixel intensities. \n","# A[i,j] is inversely proportional to the squared distance of\n","# lamp j to pixel i.\n","A = np.zeros((m, n)) # intensity matrix for m grids and n lamps.T\n","\n","for i in range(m): # iterate over m grids.\n","    for j in range(n): # iterate over n lamps.\n","        A[i, j] = 1/(norm(mesh[i] - lamps[j]))**2 # intensity ~ inverse of distance\n","print(A.shape)\n","\n","A = (m/np.sum(A)) * A # scale elements of A\n","\n","# solve least squares equation.\n","x = np.linalg.pinv(A) @ np.ones((625, 1))\n","\n","# compute rms error.\n","rms_ls = (sum((A @ x - 1)**2)/m)**0.5\n","print(rms_ls)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(625, 10)\n","[0.14039048]\n"]}]},{"cell_type":"markdown","metadata":{"id":"k9tJvwg5A70M"},"source":["Let's visualize the histogram for intensity for each pixel."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"RWmQ0P8dA70N","executionInfo":{"status":"ok","timestamp":1639023806179,"user_tz":-540,"elapsed":65,"user":{"displayName":"­이은후 / 학생 / 기계공학부","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv9QcASZ-Lrf5DcEF1J-lMM6zD0EnbwVb9y6c=s64","userId":"18289783074241175467"}},"outputId":"caee0d20-1e64-459b-95cd-07bff3cdbd29"},"source":["plt.hist(A @ x, bins = 25)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"N2A_0JYlA70O"},"source":["## Problem 2. Classification of IRIS flower dataset.\n","\n","Now we conduct the classification problem using IRIS dataset.\n","First, let's prepare the IRIS flower dataset.\n","\n","In addition we take the least squares classifier based on the regression model,\n","as shown in pp.289 of our textbook."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fvqJPfTPA70P","executionInfo":{"status":"ok","timestamp":1639023810803,"user_tz":-540,"elapsed":4675,"user":{"displayName":"­이은후 / 학생 / 기계공학부","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv9QcASZ-Lrf5DcEF1J-lMM6zD0EnbwVb9y6c=s64","userId":"18289783074241175467"}},"outputId":"1d000d68-2a7b-4dd6-9248-e1389047a292"},"source":["! pip install sklearn\n","import sklearn\n","from sklearn.datasets import load_iris\n","iris = load_iris()\n","\n","X = iris['data'] # (150, 4)\n","# first 50 rows are for 'setosa', next 50 rows are 'versicolor', and the last 50 are 'virginica'\n","\n","# we simplify the problem as binary classification. y is 1 for 'virginical' and -1 otherwise.\n","y = 2 * np.concatenate([np.zeros(100), np.ones(50)]) - 1. # (150,)\n","\n","# we add the offset 'v' as all ones-array to create regression model.\n","\n","A = np.concatenate([np.ones((150, 1)), X], axis=-1) # [150, 5]\n","\n","# find regression model parameter thetas\n","\n","theta = np.linalg.pinv(A) @ y # [5,]\n","\n","# show the predictions. Check if the prediction is True (>0) or False (<=0).\n","results = (A @ theta) > 0\n","print(results)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.0.0)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n","[False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False  True False False False False  True False False False\n"," False False False False False False  True False False False  True False\n"," False False False False False  True False False False False False False\n","  True  True False False False False False False False False False False\n"," False False False False  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True False\n","  True  True  True  True  True  True  True  True  True False  True  True\n","  True False False  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True]\n"]}]},{"cell_type":"code","metadata":{"id":"y_2w4N85A70P"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Thl_JtyzA70Q"},"source":["## Problem 3. Multi-class classification of IRIS dataset.\n","Now, we will conduct multi-class classification of the IRIS dataset."]},{"cell_type":"markdown","metadata":{"id":"LOiGN_gHA70R"},"source":["As shown in the textbook, the $K$-class classifier can be expressed as \n","\n","$\n","\\hat{f}({\\mathbf{x}})=\\argmax_k \\tilde{f}_k(\\mathbf{x}).\n","$\n","\n","We can simplify this as matrix-vector notation as\n","\n","$\n","\\hat{f}({\\mathbf{x}})=\\argmax \\mathbf{x}^{\\top}\\Theta,\n","$\n","\n","where $\\Theta=[\\theta_1, \\cdots, \\theta_K] \\in \\mathbb{R}^{n \\times K}$.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7vuWb9PfA70R","executionInfo":{"status":"ok","timestamp":1639023810806,"user_tz":-540,"elapsed":113,"user":{"displayName":"­이은후 / 학생 / 기계공학부","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv9QcASZ-Lrf5DcEF1J-lMM6zD0EnbwVb9y6c=s64","userId":"18289783074241175467"}},"outputId":"f55b18d2-9475-4dd9-ba3b-2c04524357fa"},"source":["\n","# we define row argmax function, that returns the index for the maximum value along each row.\n","# Thus, for K columns and N samples, we can find the maximum values among K class predictions.\n","# we use python's Lambda function for convenience. \n","# please refer to this: https://stackabuse.com/lambda-functions-in-python/\n","\n","# iterate for each row by index i, and find the maximum value for among columns.\n","row_argmax = lambda u: [ np.argmax(u[i]) for i in range(len(u))]\n","\n","# test our lambda function.\n","A = np.random.normal(size = (4, 5))\n","print(A)\n","print(row_argmax(A))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.70954197  3.04564803 -0.50479895  0.87804758  0.17338234]\n"," [ 0.42331139  1.27055367 -0.15251485  1.05670119  0.33340286]\n"," [-0.53197877  0.48467824  0.02402072  0.32268442  1.22189543]\n"," [-0.36430373 -0.86995265  0.63712168 -1.47172834  0.16037026]]\n","[1, 1, 4, 2]\n"]}]},{"cell_type":"code","metadata":{"id":"QVkRBhf5A70S"},"source":["# we also define a one-hot function that changes the label into one-hot vector.\n","# please refer to this for more information about one-hot vector.\n","# https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n","# ycl이 정수 label들이 들어있는 것으로 생각해야 한다. \n","\n","def one_hot(ycl, K):\n","\n","    N = len(ycl) # get the amount of labels.\n","    Y = np.zeros((N, K)) # dummy matrix.\n","    for j in range(K): # iterate over K classes\n","        for i in range(N):\n","          if (ycl[i] == j):\n","            Y[i][j] = 1  # set element to 1 if class index is equal to index j.\n","    return Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4onrNLSDA70T"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G2C3TD-oA70T"},"source":["# multi-class least-squares solver\n","def ls_multiclass(X, ycl, K):\n","    \"\"\"\n","        X: training data # [6, 120]\n","        ycl: class labels. # [120, ]\n","        K: number of .# 3\n","    \"\"\"\n","    # get one_hot labels.\n","    one_hot_label = one_hot(ycl, K)\n","\n","    # change into singed labels.\n","    signed_label = 2*one_hot_label - np.ones((len(ycl), K)) #[N*K]\n","\n","    # solve matrix form least squares\n","    theta_cols = []\n","    for i in range(K): # iterate over K columns\n","        theta = np.linalg.pinv(X.T) @ signed_label[:, i] # solve least squares\n","        theta_cols.append(theta)\n","    Theta = np.array(theta_cols) # get theta matrix [N*K]\n","\n","    # get prediction\n","    yhat = np.array(row_argmax(X.T @ Theta.T))\n","    return Theta, yhat"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nv5TOXH7A70U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639023810809,"user_tz":-540,"elapsed":61,"user":{"displayName":"­이은후 / 학생 / 기계공학부","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv9QcASZ-Lrf5DcEF1J-lMM6zD0EnbwVb9y6c=s64","userId":"18289783074241175467"}},"outputId":"5238182a-dfb4-4ea0-d032-d80db2780b76"},"source":["# shuffle dataset for each class. Use this indices to create train/test split.\n","I1 = np.random.permutation(50) # 0부터 49까지의 수가 들어있는 배열\n","I2 = np.random.permutation(50) + 50\n","I3 = np.random.permutation(50) + 100\n","\n","# training set consists of 40 randomly picked examples per class\n","Xtrain = np.vstack(\n","    [\n","      # random.sample은 배열에서 값을 임의로 추출하는 함수\n","      np.hstack([I1[10:50], I2[10:50], I3[10:50]]),\n","      np.hstack([I1[0:10], I1[20:50], I2[0:10], I2[20:50], I3[0:10], I3[20:50]]),\n","      np.hstack([I1[0:20], I1[30:50], I2[0:20], I2[30:50], I3[0:20], I3[30:50]]),\n","      np.hstack([I1[0:30], I1[40:50], I2[0:30], I2[40:50], I3[0:30], I3[40:50]]),\n","      np.hstack([I1[0:40], I2[0:40], I3[0:40]])\n","     ]) # [5, 120]\n","\n","# add contant feature one\n","Xtrain = np.vstack([np.ones(120), Xtrain]) # [6, 120]\n","\n","# the true labels for train set are a sequence of 0s, 1s and 2s\n","# since the examples in Xtrain are stacked in order\n","ytrain = np.hstack([np.zeros(40), np.ones(40), 2 * np.ones(40)]) # [120, ]\n","\n","# test set is remaining 10 examples for each class Xtest\n","Xtest = np.vstack(\n","    [\n","    np.hstack([I1[0:10], I2[0:10], I3[0:10]]),\n","    np.hstack([I1[10:20], I2[10:20], I3[10:20]]),\n","    np.hstack([I1[20:30], I2[20:30], I3[20:30]]),\n","    np.hstack([I1[30:40], I2[30:40], I3[30:40]]),\n","    np.hstack([I1[40:50], I2[40:50], I3[40:50]]),\n","    ])\n","\n","Xtest = np.vstack([np.ones(30), Xtest]) # [6, 30]\n","ytest = np.hstack([np.zeros(10), np.ones(10), 2 * np.ones(10)]) # [30, ]\n","\n","# get the Theta matrix\n","Theta, yhat = ls_multiclass(Xtrain, ytrain, 3)\n","\n","# compute rms error for training set\n","rms_train = (sum((yhat - ytrain)**2)/ 120)**0.5\n","\n","print(rms_train)\n","\n","# check for the test set\n","y_hat_test = row_argmax(Xtest.T @ Theta.T)\n","#print(Xtest.T@Theta.T)\n","rms_test = (sum((y_hat_test - ytest)**2)/ 30)**0.5\n","\n","print(rms_test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.48304589153964794\n","0.5477225575051661\n"]}]},{"cell_type":"code","metadata":{"id":"4EbSu3nyA70V"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n69SDsc_A70V"},"source":[""],"execution_count":null,"outputs":[]}]}